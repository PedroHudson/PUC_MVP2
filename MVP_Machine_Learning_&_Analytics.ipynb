{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSKQdTbMmezNpl2a+5fvF7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroHudson/PUC_MVP2/blob/main/MVP_Machine_Learning_%26_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MVP - Machine Learning & Analytics**\n",
        "\n",
        "1. Este projeto visa treinar dois modelos de Machine Learning, um modelo utilizando os métodos clássicos para um problema de classificação (Projeto A), e outro utilizando Deep Learning para um problema de linguagem natural (Projeto B).\n",
        "\n",
        "**Projeto A**\n",
        "\n",
        "**1. Definição do Problema:**\n"
      ],
      "metadata": {
        "id": "UmHETL_W42it"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Importação das Bibliotecas e Configurações.**"
      ],
      "metadata": {
        "id": "Lm1q_c115_Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração para não exibir Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Importação do Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Importação do Numpy\n",
        "import numpy as np\n",
        "\n",
        "# Importação do Pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importações dos modelos e configurações para treinamento do modelo, criação de pipelines, ensembles e para a apuração do resultado\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Importações para Feature Selection\n",
        "from sklearn.feature_selection import SelectKBest # para a Seleção Univariada\n",
        "from sklearn.feature_selection import f_classif # para o teste ANOVA da Seleção Univariada\n",
        "\n",
        "# Transformações Númericas\n",
        "\n",
        "# Normalização\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Padronização\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n"
      ],
      "metadata": {
        "id": "cvqxcu-K6k37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}